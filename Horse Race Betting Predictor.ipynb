{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#drop rows with n/a values\n",
    "horses = pd.read_csv('Downloads/race-result-horse.csv')\n",
    "horses=horses.dropna()\n",
    "\n",
    "#Drop horses that did not finish or were disqualified, or for some reason did not have a legit finishing position\n",
    "list1=['4 DH','3 DH','5 DH','2 DH','6 DH','1 DH','8 DH','PU','7 DH','10 DH','9 DH','UR','FE','11 DH','DNF','12 DH','DISQ']\n",
    "horses = horses[~horses.finishing_position.isin(list1)]\n",
    "\n",
    "#Drop running position from data, presumably you will be betting money before this information is known\n",
    "horses = horses.drop(['running_position_1','running_position_2','running_position_3'], axis=1)\n",
    "\n",
    "#Change Data types\n",
    "horses = horses.astype({'finishing_position':'int32','actual_weight':'int32','declared_horse_weight':'int32','draw':'int32','win_odds':'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finishing_position\n",
       "1      9.108556\n",
       "2     12.219456\n",
       "3     15.503064\n",
       "4     18.380556\n",
       "5     21.955318\n",
       "6     24.826172\n",
       "7     28.454382\n",
       "8     33.123529\n",
       "9     36.784295\n",
       "10    43.161327\n",
       "11    46.303522\n",
       "12    53.546634\n",
       "13    58.836583\n",
       "14    66.307279\n",
       "Name: win_odds, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Treat categorical variables with mean encoding. There are way too many labels for dummy columns. \n",
    "horse_name_encode = horses.groupby('horse_name')['finishing_position'].mean()\n",
    "horses.loc[:, 'horse_name_replacement'] = horses['horse_name'].map(horse_name_encode)\n",
    "\n",
    "horse_name_encode = horses.groupby('jockey')['finishing_position'].mean()\n",
    "horses.loc[:, 'jockey_replacement'] = horses['jockey'].map(horse_name_encode)\n",
    "\n",
    "horse_name_encode = horses.groupby('trainer')['finishing_position'].mean()\n",
    "horses.loc[:, 'trainer_replacement'] = horses['trainer'].map(horse_name_encode)\n",
    "\n",
    "#Drop original columns\n",
    "horses=horses.drop(['horse_name','jockey','trainer'], axis=1)\n",
    "\n",
    "#Establish a benchmark for performance. The goal of this algorithm is to make profitable bets. \n",
    "horses.groupby('finishing_position')['win_odds'].mean()\n",
    "#The above code shows the average betting odds of a winning horse is 9.108. This mean the model should be correctly predicting the result 1/10.108 times to \n",
    "#break even. If it can correctly predict better than that, the algorithm will make money. This translates to a percentage of 9.9% accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get train and test sets. \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "horses=horses.values\n",
    "X = horses[:,1:6]\n",
    "y = horses[:,0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "#Scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scale_X_train = scaler.fit_transform(X_train)\n",
    "scale_X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14166524774391281"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First attempt at prediction, simple logistic regression with no frills\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr= LogisticRegression(max_iter=1000)\n",
    "lr.fit(scale_X_train, y_train)\n",
    "\n",
    "lr.score(scale_X_test, y_test)\n",
    "\n",
    "#This gives an accuracy score of ~14%. This is accurate enough to be profitable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11169759918270049"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Second attempt at prediction, with simple K Nearest neighbors, again no frills\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn= KNeighborsClassifier()\n",
    "knn.fit(scale_X_train, y_train)\n",
    "\n",
    "knn.score(scale_X_test, y_test)\n",
    "\n",
    "#This gives an accuracy score of ~11%. This is accurate enough to be profitable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14500747196216374\n",
      "{'max_iter': 250, 'tol': 0.005}\n"
     ]
    }
   ],
   "source": [
    "#logisticregression with a grid search. \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tol = [.005, .01, .015]\n",
    "max_iter = [250,500,750]\n",
    "\n",
    "param_grid= dict(tol=tol, max_iter=max_iter)\n",
    "\n",
    "grid = GridSearchCV(estimator=lr, param_grid=param_grid, cv=5)\n",
    "\n",
    "scaledX=scaler.fit_transform(X)\n",
    "\n",
    "result=grid.fit(scaledX, y)\n",
    "\n",
    "print(result.best_score_)\n",
    "print(result.best_params_)\n",
    "\n",
    "#This gave an accuracy score of 14.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12293968356553404\n",
      "{'n_neighbors': 20}\n"
     ]
    }
   ],
   "source": [
    "#Grid Search with KNN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_neighbors = [15,20,25]\n",
    "\n",
    "param_grid= dict(n_neighbors=n_neighbors)\n",
    "\n",
    "grid = GridSearchCV(estimator=knn, param_grid=param_grid, cv=5)\n",
    "\n",
    "scaledX=scaler.fit_transform(X)\n",
    "\n",
    "result=grid.fit(scaledX, y)\n",
    "\n",
    "print(result.best_score_)\n",
    "print(result.best_params_)\n",
    "#This offered a modest improvement, bumping it from 11% to about 12% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming the 'finishing position' column into a binary variable. The two options will be winner and non-winner. \n",
    "horses['winner'] = horses['finishing_position'] == 1\n",
    "horses=horses.drop(['finishing_position'], axis=1)\n",
    "horses['winner'] = horses['winner'].astype('int32')\n",
    "\n",
    "#Get train and test sets. \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "horses=horses.values\n",
    "X = horses[:,0:7]\n",
    "y = horses[:,7]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "#Scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scale_X_train = scaler.fit_transform(X_train)\n",
    "scale_X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scale_X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-83de1ab60dd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mLogisticRegressionCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale_X_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scale_X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#Try logisticRegression again, this time with the new binary variables\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "lr= LogisticRegressionCV(cv=5,max_iter=1000)\n",
    "lr.fit(scale_X_train, y_train)\n",
    "\n",
    "print(lr.score(scale_X_test, y_test))\n",
    "y_pred=lr.predict(scale_X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "#Accuracy jumps to 92%, however, on closer inspection, the model is simply predicting 'non-winner' every time. I need to change\n",
    "#class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.920313298144049\n",
      "[[5395    3]\n",
      " [ 465   10]]\n",
      "0.919121403030819\n",
      "[[5398    0]\n",
      " [ 475    0]]\n",
      "0.9184403201089733\n",
      "[[5376   22]\n",
      " [ 457   18]]\n"
     ]
    }
   ],
   "source": [
    "#Try a bunch of class weights\n",
    "for a in [1.5,3.5,4.5]:\n",
    "    lr= LogisticRegressionCV(cv=5,max_iter=1000, class_weight={1:a})\n",
    "    lr.fit(scale_X_train, y_train)\n",
    "\n",
    "    print(lr.score(scale_X_test, y_test))\n",
    "    y_pred=lr.predict(scale_X_test)\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    \n",
    "#As the class_weight increases, accuracy decreases. However, this is an acceptable trade-off. The model is finally starting\n",
    "#to predict some winners as well. \n",
    "\n",
    "#At a class weight of 1.5, the model predicts 13 winners, 10 are actually correct. \n",
    "#This is an accuracy rate of 77% when guessing winner. At a class weight of 4.5,\n",
    "#the model predicts 40 winners, of which 18 are correct. This is an accuracy rate\n",
    "#of 45% when guessing winner. Going back to the original odds calculation, both these\n",
    "#accuracy rates are high enough to be profitable. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
